{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episodes in range(500):\n",
    "    behavior.toymodel.save('120220_SMB')\n",
    "    time.sleep(3)\n",
    "    reset_input()\n",
    "    load_save_state()\n",
    "    done = False\n",
    "    for i in range (3):\n",
    "        state_0 = collect_frames()\n",
    "        \n",
    "        #Check if game is over.This should yield a very negative result.\n",
    "        done = gameover()\n",
    "\n",
    "        if done:\n",
    "            reward = -5\n",
    "            future_rewards = behavior.toymodel.predict([np.expand_dims(state_1[0],0),np.expand_dims(state_1[1],0)])\n",
    "            updated_q_values = reward + gamma * tf.reduce_max(future_rewards, axis=1)\n",
    "            with tf.GradientTape() as tape:  \n",
    "                q_values = behavior.forward([np.expand_dims(state_0[0],0),np.expand_dims(state_0[1],0)])\n",
    "                loss = behavior.loss_fn(updated_q_values, q_values)   \n",
    "            grads = tape.gradient(loss, behavior.toymodel.trainable_variables)\n",
    "            print (loss)\n",
    "            behavior.toymodel.optimizer.apply_gradients(zip(grads, behavior.toymodel.trainable_variables))\n",
    "            break\n",
    "        #Collect score before new state.   \n",
    "        try:\n",
    "            score_0 = score()\n",
    "        except ValueError:\n",
    "            score_1 = 0\n",
    "            score_0 = 0\n",
    "            \n",
    "        if np.random.random() < epsilon:\n",
    "            a = np.random.choice(np.arange(0,7))\n",
    "        else:\n",
    "            a = np.argmax(behavior.forward([np.expand_dims(state_0[0],0),np.expand_dims(state_0[1],0)]))\n",
    "        trade_off(a)\n",
    "        state_1 = collect_frames()\n",
    "        try:\n",
    "            score_1 = score()\n",
    "        except ValueError:\n",
    "            score_1 = 0\n",
    "            score_0 = 0\n",
    "            \n",
    "        reward = calculate_reward(score_1, score_0) \n",
    "        \n",
    "        state_history.append(state_0)\n",
    "        next_state_history.append(state_1)\n",
    "        done_history.append(done)\n",
    "        reward_history.append(reward)\n",
    "    \n",
    "    future_rewards = behavior.toymodel.predict(next_state_history)\n",
    "    updated_q_values = reward + gamma * tf.reduce_max(future_rewards, axis=1)\n",
    "    with tf.GradientTape() as tape:  \n",
    "        q_values = behavior.forward(state_history)\n",
    "        loss = behavior.loss_fn(updated_q_values, q_values)\n",
    "    loss_history.append(loss)\n",
    "    grads = tape.gradient(loss, behavior.toymodel.trainable_variables)\n",
    "    behavior.toymodel.optimizer.apply_gradients(zip(grads, behavior.toymodel.trainable_variables))\n",
    "\n",
    "        #behavior.trainStep([np.expand_dims(state_0[0],0),np.expand_dims(state_0[1],0)], reward)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for episodes in range(500):\n",
    "    behavior.toymodel.save('120220_SMB')\n",
    "    time.sleep(3)\n",
    "    reset_input()\n",
    "    load_save_state()\n",
    "    done = False\n",
    "    for i in range (50):\n",
    "        state_0 = collect_frames()\n",
    "\n",
    "        #Check if game is over.This should yield a very negative result.\n",
    "        done = gameover()\n",
    "        if done:\n",
    "            reward = -5\n",
    "            future_rewards = behavior.toymodel.predict([np.expand_dims(state_1[0],0),np.expand_dims(state_1[1],0)])\n",
    "            updated_q_values = reward + gamma * tf.reduce_max(future_rewards, axis=1)\n",
    "            with tf.GradientTape() as tape:  \n",
    "                q_values = behavior.forward([np.expand_dims(state_0[0],0),np.expand_dims(state_0[1],0)])\n",
    "                loss = behavior.loss_fn(updated_q_values, q_values)   \n",
    "            grads = tape.gradient(loss, behavior.toymodel.trainable_variables)\n",
    "            print (loss)\n",
    "            behavior.toymodel.optimizer.apply_gradients(zip(grads, behavior.toymodel.trainable_variables))\n",
    "            break\n",
    "        #Collect score before new state.   \n",
    "        try:\n",
    "            score_0 = score()\n",
    "        except ValueError:\n",
    "            score_1 = 0\n",
    "            score_0 = 0\n",
    "            \n",
    "        if np.random.random() < epsilon:\n",
    "            a = np.random.choice(np.arange(0,7))\n",
    "        else:\n",
    "            a = np.argmax(behavior.forward([np.expand_dims(state_0[0],0),np.expand_dims(state_0[1],0)]))\n",
    "        trade_off(a)\n",
    "        state_1 = collect_frames()\n",
    "        try:\n",
    "            score_1 = score()\n",
    "        except ValueError:\n",
    "            score_1 = 0\n",
    "            score_0 = 0\n",
    "            \n",
    "        reward = calculate_reward(score_1, score_0) \n",
    "        future_rewards = behavior.toymodel.predict([np.expand_dims(state_1[0],0),np.expand_dims(state_1[1],0)])\n",
    "        updated_q_values = reward + gamma * tf.reduce_max(future_rewards, axis=1)\n",
    "        with tf.GradientTape() as tape:  \n",
    "            q_values = behavior.forward([np.expand_dims(state_0[0],0),np.expand_dims(state_0[1],0)])\n",
    "            loss = behavior.loss_fn(updated_q_values, q_values)\n",
    "        loss_history.append(loss)\n",
    "        grads = tape.gradient(loss, behavior.toymodel.trainable_variables)\n",
    "        behavior.toymodel.optimizer.apply_gradients(zip(grads, behavior.toymodel.trainable_variables))\n",
    "    \n",
    "        #behavior.trainStep([np.expand_dims(state_0[0],0),np.expand_dims(state_0[1],0)], reward)\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
