{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#import retro\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "#import keyboard\n",
    "import gym\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import clear_output\n",
    "#retro.data.list_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs, rew, done, info = env.step(env.action_space.sample())\n",
    "#(224, 240, 3)\n",
    "#MultiBinary(9)                          \n",
    "class RAM_ANN():\n",
    "  def __init__(self, action_space, frameskip, seed):\n",
    "    initializer1 = initializers.GlorotUniform (seed = seed+1)\n",
    "    initializer2 = initializers.GlorotUniform (seed = seed+2)\n",
    "    initializer3 = initializers.GlorotUniform (seed = seed+3)\n",
    "    initializer4 = initializers.GlorotUniform (seed = seed+4)\n",
    "\n",
    "    self.frameskip = frameskip\n",
    "    self.action_space = len(action_space)\n",
    "    num_actions = self.action_space\n",
    "    #NN layers\n",
    "    ram_input = layers.Input(shape=(128,self.frameskip))\n",
    "    #preprocessor = layers.experimental.preprocessing.Resizing(84, 84, interpolation='bilinear', name=None)(image_input)\n",
    "    # Convolutions on the frames on the screen\n",
    "    #data_format='channels_first'\n",
    "    layer4 = layers.Flatten()(ram_input)\n",
    "    layer5 = layers.Dense(128, activation=\"relu\", kernel_initializer = initializer1)(layer4)\n",
    "    layer6 = layers.Dense(128, activation=\"relu\", kernel_initializer = initializer2)(layer5)\n",
    "    layer7 = layers.Dense(128, activation=\"relu\", kernel_initializer = initializer3)(layer6)\n",
    "    action = layers.Dense(num_actions, activation=\"linear\", kernel_initializer = initializer4)(layer7)\n",
    "\n",
    "    #Define NN parameters.\n",
    "    self.toymodel = keras.Model(inputs=ram_input, outputs=action)\n",
    "    self.loss_fn = tf.keras.losses.Huber()\n",
    "    self.optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "    self.toymodel.compile(self.optimizer, self.loss_fn)\n",
    "\n",
    "  def trainStep(self, sample_X, sample_Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      old_q = self.toymodel(sample_X, training=True)\n",
    "      loss_value = self.loss_fn(sample_Y, old_q)\n",
    "    grads = tape.gradient(loss_value, self.toymodel.trainable_weights)\n",
    "    self.optimizer.apply_gradients(zip(grads, self.toymodel.trainable_weights))\n",
    "    return loss_value.numpy()\n",
    "\n",
    "  def train(self, x_input, y_input, batchsize=64):\n",
    "    loss_history = []\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_input, y_input))\n",
    "    dataset = dataset.shuffle(buffer_size=1024).batch(batchsize)\n",
    "    for steps, (x, y) in enumerate(dataset):\n",
    "      loss_history.append(self.trainStep(x,y))\n",
    "    return loss_history\n",
    "\n",
    "  def forward(self, x_input):\n",
    "    return self.toymodel(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class Agent_RAM():\n",
    "    def __init__(self,runname, env, action_space):\n",
    "        self.seed = 42\n",
    "        self.action_space = action_space\n",
    "        self.env = env\n",
    "        self.env.seed(self.seed)\n",
    "        self.steps_taken = 0 \n",
    "        self.runname = runname\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_min = 0.05\n",
    "        self.epsilon_lag = 50000\n",
    "        self.annealing_time = 1000000\n",
    "        self.len_of_episode = 10000\n",
    "        self.gamma = 0.80\n",
    "        self.max_memory_len = 100000\n",
    "        self.steps_per_update = 100\n",
    "        self.batch_size = 32\n",
    "        self.loss_history = []\n",
    "        self.action_history = []\n",
    "        self.state_history= []\n",
    "        self.next_state_history = []\n",
    "        self.reward_history = []\n",
    "        self.done_history = []\n",
    "        self.episodic_return = []\n",
    "        self.return_history = [] \n",
    "        self.frameskip = 8 \n",
    "        self.behavior = RAM_ANN(self.action_space, self.frameskip, self.seed)\n",
    "        self.target = RAM_ANN(self.action_space,self.frameskip, self.seed)\n",
    "        self.target_update = 100\n",
    "        \n",
    "    def popback(self, state_block, incoming_state):\n",
    "        state_block.pop(0)\n",
    "        state_block.append(incoming_state)\n",
    "        return state_block\n",
    "\n",
    "    def gradient_update(self, \n",
    "                        runname,\n",
    "                        state_history, \n",
    "                        next_state_history,\n",
    "                        rewards_history,\n",
    "                        action_history,\n",
    "                        loss_history,\n",
    "                        model,\n",
    "                        target_model,\n",
    "                        gamma,\n",
    "                        batch_size,\n",
    "                        done_history,\n",
    "                        action_space,\n",
    "                        seed,\n",
    "                        steps):\n",
    "            np.random.seed(seed+steps)\n",
    "            # Get indices of samples for replay buffers\n",
    "            indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
    "            # Using list comprehension to sample from replay buffer\n",
    "            state_sample = np.array([state_history[i] for i in indices])\n",
    "            next_state_sample = np.array([next_state_history[i] for i in indices])\n",
    "            rewards_sample = [rewards_history[i] for i in indices]\n",
    "            action_sample = [action_history[i] for i in indices]\n",
    "            done_sample = tf.convert_to_tensor([float(done_history[i]) for i in indices])\n",
    "            future_rewards = target_model.toymodel.predict(next_state_sample)\n",
    "            updated_q_values = rewards_sample + gamma * tf.reduce_max(future_rewards, axis=1)\n",
    "            updated_q_values = updated_q_values *(1-done_sample) - done_sample\n",
    "            updated_q_values = np.interp(updated_q_values, (-1, np.max(updated_q_values)), (-1,1))        #Normalize the rewards. \n",
    "            masks = tf.one_hot(action_sample, len(action_space))\n",
    "            with tf.GradientTape() as tape:  \n",
    "                q_values = model.toymodel(state_sample)\n",
    "                q_actions = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "                loss = model.loss_fn(updated_q_values, q_actions)\n",
    "            loss_history.append(loss)\n",
    "            grads = tape.gradient(loss, model.toymodel.trainable_variables)\n",
    "            model.toymodel.optimizer.apply_gradients(zip(grads, model.toymodel.trainable_variables))\n",
    "            \n",
    "            #np.save(runname + 'loss_function_history', loss_history)\n",
    "            \n",
    "    def save_history(self,\n",
    "                     runname,\n",
    "                     action_history,\n",
    "                     state_history,\n",
    "                     next_state_history,\n",
    "                     reward_history,\n",
    "                     done_history,\n",
    "                     return_history):            \n",
    "        np.save(runname + 'action_history',action_history)\n",
    "        np.save(runname + 'state_history', state_history)\n",
    "        np.save(runname + 'next_state_history', next_state_history)\n",
    "        np.save(runname + 'reward_history', reward_history)\n",
    "        np.save(runname + 'done_history', done_history)\n",
    "        np.save(runname + 'return_history', return_history)   \n",
    "\n",
    "    def preprocess(self, image):\n",
    "        return np.array(image/255).astype('float16')\n",
    "\n",
    "    def memory_manager(self,array, mem_size):\n",
    "        num_delete = len(array) - mem_size\n",
    "        if num_delete < 0:\n",
    "            None\n",
    "        else:\n",
    "            del array[:num_delete]\n",
    "            \n",
    "    def piecewise_epsilon(self, steps_taken, lag, annealingtime, ep_min, ep_max): #returns epsilon\n",
    "        anneal_slope= (ep_min-ep_max)/(lag+annealingtime-lag)\n",
    "        if steps_taken < lag: return ep_max\n",
    "        if (steps_taken >= lag) and (steps_taken < (lag+annealingtime)): return anneal_slope*steps_taken+(ep_max-anneal_slope*lag)\n",
    "        else: return ep_min\n",
    "        \n",
    "    def episode(self,num_episodes):    #Double Deep Q\n",
    "        np.random.seed(self.seed+self.steps_taken)\n",
    "        for episode_number in range (num_episodes):\n",
    "            \n",
    "            #Calculate epsilon using a piecewise function.\n",
    "            self.epsilon = self.piecewise_epsilon(self.steps_taken, self.epsilon_lag, self.annealing_time, self.epsilon_min, self.epsilon_max)\n",
    "                \n",
    "            lives = 5     #5 for Breakout, 3 for Space Invaders\n",
    "            s = []\n",
    "            s.append(self.preprocess(self.env.reset()))\n",
    "            #Setup initial environment.                                                            #FUNCTIONIZE\n",
    "            #Prime the state s with 3 frames.\n",
    "            epi_return = 0 \n",
    "            for i in range(self.frameskip-1):\n",
    "                frame, r, done, info = self.env.step(self.action_space[1])\n",
    "                epi_return += r\n",
    "                s.append(self.preprocess(frame))\n",
    "\n",
    "            done = False\n",
    "            \n",
    "            #Choose an initial action.\n",
    "            \n",
    "            if np.random.random() < np.max([self.epsilon,self.epsilon_min]):\n",
    "                a = np.random.choice(np.arange(len(self.action_space)))\n",
    "\n",
    "            else: \n",
    "                a_probs = self.behavior.toymodel(np.expand_dims(np.dstack(s)[0],0), training=False)\n",
    "                a = tf.argmax(a_probs[0]).numpy()\n",
    "\n",
    "            #Enter the loop.\n",
    "            for step_in_episode in range (self.len_of_episode):\n",
    "                reward = 0\n",
    "                #Skip 4 frames.\n",
    "                new_frame, r, done, info = self.env.step(self.action_space[a])\n",
    "                s_prime = self.popback(s, self.preprocess(new_frame))\n",
    "                reward += r\n",
    "                #for j in range(self.frameskip-1): #If you want to repeat actions enable this line.\n",
    "                #  new_frame, r, done, info = self.env.step(self.action_space[a])\n",
    "                #  s_prime = self.popback(s_prime, self.preprocess(new_frame))\n",
    "                #  reward += r        \n",
    "                \n",
    "                epi_return += reward\n",
    "                #self.env.render()\n",
    "                #Restart when the end of the episode is reached.  \n",
    "                if done:                                                                              #FUNCTIONIZE!\n",
    "                    #Set the last frame to -1 to discourage dying.                                             \n",
    "                    self.done_history[-1] = True                       \n",
    "                    self.episodic_return.append(epi_return)\n",
    "                    break\n",
    "                #Monitor the the number of lives from the environemtnt. If the number of lives is reduced, then the player has died. Reset the level.  FUNCTIONIZE!\n",
    "                if not (int(info['ale.lives']) == lives):                                         \n",
    "                    self.done_history[-1] = True \n",
    "                    self.episodic_return.append(epi_return)\n",
    "                    #print ('Episode finished in ', step_in_episode, 'steps.')\n",
    "                    break\n",
    "                    #epi_return = 0\n",
    "                    #reward = 0\n",
    "                    #lives = info['ale.lives'] #Reduce the number of lives.\n",
    "                    #s = []\n",
    "                    ##Prime the state s with 4 frames. Don't restart environment. Keep playing the same level. Prime with 4 frames while hitting \"FIRE\" to start next round.\n",
    "                    #epi_return = 0 \n",
    "                    #for i in range(self.frameskip):\n",
    "                    #    frame, reward, done, info = self.env.step(self.action_space[1])\n",
    "                    #    epi_return += reward\n",
    "                    #    s.append(self.preprocess(frame))\n",
    "                    #if np.random.random() < np.max([self.epsilon,self.epsilon_min]):\n",
    "                    #    a = np.random.choice(np.arange(len(self.action_space)))\n",
    "                    #else: \n",
    "                    #    a_probs = self.behavior.toymodel(np.expand_dims(np.dstack(s)[0],0), training=False)\n",
    "                    #    a = tf.argmax(a_probs[0]).numpy()\n",
    "                    #reward = 0\n",
    "                    ##Skip 4 frames.\n",
    "                    #new_frame, r, done, info = self.env.step(self.action_space[a])\n",
    "                    #s_prime = self.popback(s, self.preprocess(new_frame))\n",
    "                    #reward += r\n",
    "                    #for j in range(self.frameskip-1): \n",
    "                    #  new_frame, r, done, info = self.env.step(self.action_space[a])\n",
    "                    #  s_prime = self.popback(s_prime, self.preprocess(new_frame))\n",
    "                    #  reward += r                    \n",
    "\n",
    "                #Save to history\n",
    "                self.reward_history.append(reward)\n",
    "                self.state_history.append(np.dstack(s)[0])\n",
    "                self.action_history.append(a)\n",
    "                self.next_state_history.append(np.dstack(s_prime)[0])\n",
    "                self.done_history.append(done)\n",
    "                 \n",
    "                if len(self.reward_history)>self.batch_size and self.steps_taken%self.steps_per_update==0:\n",
    "                    self.gradient_update(self.runname,\n",
    "                                         self.state_history, \n",
    "                                         self.next_state_history,\n",
    "                                         self.reward_history,\n",
    "                                         self.action_history,\n",
    "                                         self.loss_history,\n",
    "                                         self.behavior, \n",
    "                                         self.behavior, #add behavior here to make it single Q-learning,\n",
    "                                         self.gamma,\n",
    "                                         self.batch_size,\n",
    "                                         self.done_history,\n",
    "                                         self.action_space,\n",
    "                                         self.seed,\n",
    "                                         self.steps_taken)\n",
    "                    \n",
    "                if self.steps_taken%self.target_update==0:\n",
    "                    self.target.toymodel.set_weights(self.behavior.toymodel.get_weights())   \n",
    "\n",
    "                if np.random.random() < np.max([self.epsilon,self.epsilon_min]):\n",
    "                    a_prime = np.random.choice(np.arange(len(self.action_space)))\n",
    "\n",
    "                else:\n",
    "                    a_probs = self.behavior.toymodel(np.expand_dims(np.dstack(s_prime)[0],0), training=False)\n",
    "                    a_prime = tf.argmax(a_probs[0]).numpy()\n",
    "\n",
    "                    #print ('Nonrandom action taken. ', a_prime)\n",
    "\n",
    "                s = s_prime\n",
    "                a = a_prime\n",
    "                self.steps_taken += 1\n",
    "                self.memory_manager(self.action_history, self.max_memory_len)\n",
    "                self.memory_manager(self.state_history, self.max_memory_len)\n",
    "                self.memory_manager(self.next_state_history, self.max_memory_len)\n",
    "                self.memory_manager(self.reward_history, self.max_memory_len)\n",
    "                self.memory_manager(self.done_history, self.max_memory_len)\n",
    "            #self.save_history(self.runname,\n",
    "            #                  self.action_history,\n",
    "            #                  self.state_history,\n",
    "            #                  self.next_state_history,\n",
    "            #                  self.reward_history,\n",
    "            #                  self.done_history,\n",
    "            #                  self.return_history)\n",
    "            self.episodic_return.append(epi_return)\n",
    "            #self.env.close()\n",
    "            if self.steps_taken%100==0:\n",
    "              clear_output()\n",
    "              print ('Epsilon is at ', self.epsilon, ' as of step ', self.steps_taken)\n",
    "              plt.figure(figsize=(10,2))\n",
    "              plt.plot(np.arange(len(self.episodic_return)), self.episodic_return)\n",
    "              plt.xlabel('Episode')\n",
    "              plt.ylabel('Return')\n",
    "              plt.show()\n",
    "              plt.figure(figsize=(10,2))\n",
    "              plt.plot(np.arange(len(self.loss_history)), self.loss_history)\n",
    "              plt.xlabel('Training Step')\n",
    "              plt.ylabel('Loss')\n",
    "              plt.show()\n",
    "        #self.behavior.toymodel.save('120228_Breakout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "env1 = gym.make('Breakout-ram-v4')\n",
    "atari_action_space = np.arange(4)\n",
    "# 'BreakoutNoFrameskip-v4'\n",
    "# 'SpaceInvaders-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon is at  0.05  as of step  1250700\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-3f182143bd55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_update\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10000\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframeskip\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000000000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-70-3e96c1b09a70>\u001b[0m in \u001b[0;36mepisode\u001b[1;34m(self, num_episodes)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_taken\u001b[0m\u001b[1;33m%\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_per_update\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                     self.gradient_update(self.runname,\n\u001b[0m\u001b[0;32m    197\u001b[0m                                          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                                          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_state_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-70-3e96c1b09a70>\u001b[0m in \u001b[0;36mgradient_update\u001b[1;34m(self, runname, state_history, next_state_history, rewards_history, action_history, loss_history, model, target_model, gamma, batch_size, done_history, action_space, seed, steps)\u001b[0m\n\u001b[0;32m     53\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[1;31m# Get indices of samples for replay buffers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdone_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[1;31m# Using list comprehension to sample from replay buffer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mstate_sample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstate_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mprod\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent = Agent_RAM('210331_1', env1, atari_action_space)\n",
    "agent.epsilon = 1.0\n",
    "agent.epsilon_max = 1.0\n",
    "agent.epsilon_min = 0.05\n",
    "agent.epsilon_lag = 50000\n",
    "agent.annealing_time = 1000000\n",
    "agent.len_of_episode = 10000\n",
    "agent.gamma = 0.99\n",
    "agent.max_memory_len = 100000\n",
    "agent.steps_per_update = 4\n",
    "agent.target_update = 10000\n",
    "agent.frameskip = 8\n",
    "agent.episode(1000000000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
