{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#import retro\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import cv2\n",
    "#import keyboard\n",
    "import gym\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import clear_output\n",
    "#retro.data.list_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs, rew, done, info = env.step(env.action_space.sample())\n",
    "#(224, 240, 3)\n",
    "#MultiBinary(9)                          \n",
    "\n",
    "class ANN():\n",
    "  def __init__(self, action_space):\n",
    "    self.action_space = len(action_space)\n",
    "    num_actions = self.action_space\n",
    "    #NN layers\n",
    "    image_input = layers.Input(shape=(84,84,4))\n",
    "    #preprocessor = layers.experimental.preprocessing.Resizing(84, 84, interpolation='bilinear', name=None)(image_input)\n",
    "    # Convolutions on the frames on the screen\n",
    "    #data_format='channels_first'\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(image_input)\n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "    layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "    action = layers.Dense(num_actions, activation=\"linear\")(layer5)\n",
    "\n",
    "    #Define NN parameters.\n",
    "    self.toymodel = keras.Model(inputs=image_input, outputs=action)\n",
    "    self.loss_fn = tf.keras.losses.Huber()\n",
    "    self.optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "    self.toymodel.compile(self.optimizer, self.loss_fn)\n",
    "\n",
    "  def trainStep(self, sample_X, sample_Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      old_q = self.toymodel(sample_X, training=True)\n",
    "      loss_value = self.loss_fn(sample_Y, old_q)\n",
    "    grads = tape.gradient(loss_value, self.toymodel.trainable_weights)\n",
    "    self.optimizer.apply_gradients(zip(grads, self.toymodel.trainable_weights))\n",
    "    return loss_value.numpy()\n",
    "\n",
    "  def train(self, x_input, y_input, batchsize=64):\n",
    "    loss_history = []\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_input, y_input))\n",
    "    dataset = dataset.shuffle(buffer_size=1024).batch(batchsize)\n",
    "    for steps, (x, y) in enumerate(dataset):\n",
    "      loss_history.append(self.trainStep(x,y))\n",
    "    return loss_history\n",
    "\n",
    "  def forward(self, x_input):\n",
    "    return self.toymodel(x_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Agent_4Frame():\n",
    "    def __init__(self,runname, env, action_space):\n",
    "        self.action_space = action_space\n",
    "        self.env = env\n",
    "        self.steps_taken = 0 \n",
    "        self.runname = runname\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_min = 0.1\n",
    "        self.annealing_time = 1000000\n",
    "        self.len_of_episode = 10000\n",
    "        self.gamma = 0.99\n",
    "        self.max_memory_len = 100000\n",
    "        self.batch_size = 32\n",
    "        self.loss_history = []\n",
    "        self.action_history = []\n",
    "        self.state_history= []\n",
    "        self.next_state_history = []\n",
    "        self.reward_history = []\n",
    "        self.done_history = []\n",
    "        self.episodic_return = []\n",
    "        self.return_history = [] \n",
    "        self.behavior = ANN(self.action_space)\n",
    "        self.target = ANN(self.action_space)\n",
    "        \n",
    "\n",
    "    def preprocess(self, image):\n",
    "        output = np.average(np.array(image), axis=2)[25:205]\n",
    "        #return output\n",
    "        return (cv2.resize(output, dsize=(84, 84), interpolation=cv2.INTER_CUBIC)/255.0).astype('float16')\n",
    "\n",
    "    def popback(self, state_block, incoming_state):\n",
    "        state_block.pop(0)\n",
    "        state_block.append(incoming_state)\n",
    "        return state_block\n",
    "\n",
    "    def gradient_update(self, \n",
    "                        runname,\n",
    "                        state_history, \n",
    "                        next_state_history,\n",
    "                        rewards_history,\n",
    "                        action_history,\n",
    "                        loss_history,\n",
    "                        model,\n",
    "                        target_model,\n",
    "                        gamma,\n",
    "                        batch_size,\n",
    "                        done_history,\n",
    "                        action_space):\n",
    "    \n",
    "            # Get indices of samples for replay buffers\n",
    "            indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
    "            # Using list comprehension to sample from replay buffer\n",
    "            state_sample = np.array([state_history[i] for i in indices])\n",
    "            next_state_sample = np.array([next_state_history[i] for i in indices])\n",
    "            rewards_sample = [rewards_history[i] for i in indices]\n",
    "            action_sample = [action_history[i] for i in indices]\n",
    "            done_sample = tf.convert_to_tensor([float(done_history[i]) for i in indices])\n",
    "            future_rewards = target_model.toymodel.predict(next_state_sample)\n",
    "            updated_q_values = rewards_sample + gamma * tf.reduce_max(future_rewards, axis=1)\n",
    "            updated_q_values = updated_q_values *(1-done_sample) - done_sample\n",
    "            masks = tf.one_hot(action_sample, len(action_space))\n",
    "            with tf.GradientTape() as tape:  \n",
    "                q_values = model.toymodel(state_sample)\n",
    "                q_actions = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "                loss = model.loss_fn(updated_q_values, q_actions)\n",
    "            loss_history.append(loss)\n",
    "            grads = tape.gradient(loss, model.toymodel.trainable_variables)\n",
    "            model.toymodel.optimizer.apply_gradients(zip(grads, model.toymodel.trainable_variables))\n",
    "            \n",
    "            np.save(runname + 'loss_function_history', loss_history)\n",
    "            \n",
    "    def save_history(self,\n",
    "                     runname,\n",
    "                     action_history,\n",
    "                     state_history,\n",
    "                     next_state_history,\n",
    "                     reward_history,\n",
    "                     done_history,\n",
    "                     return_history):            \n",
    "        np.save(runname + 'action_history',action_history)\n",
    "        np.save(runname + 'state_history', state_history)\n",
    "        np.save(runname + 'next_state_history', next_state_history)\n",
    "        np.save(runname + 'reward_history', reward_history)\n",
    "        np.save(runname + 'done_history', done_history)\n",
    "        np.save(runname + 'return_history', return_history)   \n",
    "        \n",
    "    def memory_manager(self,array, mem_size):\n",
    "        num_delete = len(array) - mem_size\n",
    "        if num_delete < 0:\n",
    "            None\n",
    "        else:\n",
    "            del array[:num_delete]\n",
    "                \n",
    "    def episode(self,num_episodes):    #Double Deep Q\n",
    "        for i in range (num_episodes):\n",
    "            self.epsilon = np.max([self.epsilon_max - (((self.epsilon_max-self.epsilon_min)/self.annealing_time)*self.steps_taken), self.epsilon_min])\n",
    "            print ('Epsilon is at ', self.epsilon, ' as of step ', self.steps_taken)\n",
    "            \n",
    "            lives = 5     #5 for Breakout, 4 for Space Invaders\n",
    "            s = []\n",
    "            s.append(self.preprocess(self.env.reset()))\n",
    "            #Setup initial environment.                                                            #FUNCTIONIZE\n",
    "            #Prime the state s with 3 frames.\n",
    "            epi_return = 0 \n",
    "            for i in range(3):\n",
    "                frame, reward, done, info = self.env.step(self.action_space[1])\n",
    "                epi_return += reward\n",
    "                s.append(self.preprocess(frame))\n",
    "\n",
    "            done = False\n",
    "            \n",
    "            #Choose an initial action.\n",
    "            if np.random.random() < np.max([self.epsilon,self.epsilon_min]):\n",
    "                a = np.random.choice(np.arange(len(self.action_space)))\n",
    "            else: \n",
    "                a_probs = self.behavior.toymodel(np.expand_dims(np.dstack(s),0), training=False)\n",
    "                a = tf.argmax(a_probs[0]).numpy()\n",
    "\n",
    "            #Enter the loop.\n",
    "            for step_in_episode in range (self.len_of_episode):\n",
    "                reward = 0\n",
    "                #Skip 4 frames.\n",
    "                new_frame, r, done, info = self.env.step(self.action_space[a])\n",
    "                s_prime = self.popback(s, self.preprocess(new_frame))\n",
    "                reward += r\n",
    "                for j in range(3): \n",
    "                  new_frame, r, done, info = self.env.step(self.action_space[a])\n",
    "                  s_prime = self.popback(s_prime, self.preprocess(new_frame))\n",
    "                  reward += r        \n",
    "                \n",
    "                epi_return += reward\n",
    "                #self.env.render()\n",
    "                #Restart when the end of the episode is reached.  \n",
    "                if done:                                                                              #FUNCTIONIZE!\n",
    "                    #Set the last frame to -1 to discourage dying.                                             \n",
    "                    self.done_history[-1] = True                       \n",
    "                    self.episodic_return.append(epi_return)\n",
    "                    break\n",
    "                #Monitor the the number of lives from the environemtnt. If the number of lives is reduced, then the player has died. Reset the level.  FUNCTIONIZE!\n",
    "                if not (int(info['ale.lives']) == lives):                                         \n",
    "                    self.done_history[-1] = True \n",
    "                    self.episodic_return.append(epi_return)\n",
    "                    epi_return = 0\n",
    "                    reward = 0\n",
    "                    lives = info['ale.lives'] #Reduce the number of lives.\n",
    "                    s = []\n",
    "                    #Prime the state s with 4 frames. Don't restart environment. Keep playing the same level. Prime with 4 frames while hitting \"FIRE\" to start next round.\n",
    "                    epi_return = 0 \n",
    "                    for i in range(4):\n",
    "                        frame, reward, done, info = self.env.step(self.action_space[1])\n",
    "                        epi_return += reward\n",
    "                        s.append(self.preprocess(frame))\n",
    "                    if np.random.random() < np.max([self.epsilon,self.epsilon_min]):\n",
    "                        a = np.random.choice(np.arange(len(self.action_space)))\n",
    "                    else: \n",
    "                        a_probs = self.behavior.toymodel(np.expand_dims(np.dstack(s),0), training=False)\n",
    "                        a = tf.argmax(a_probs[0]).numpy()\n",
    "                    reward = 0\n",
    "                    #Skip 4 frames.\n",
    "                    new_frame, r, done, info = self.env.step(self.action_space[a])\n",
    "                    s_prime = self.popback(s, self.preprocess(new_frame))\n",
    "                    reward += r\n",
    "                    for j in range(3): \n",
    "                      new_frame, r, done, info = self.env.step(self.action_space[a])\n",
    "                      s_prime = self.popback(s_prime, self.preprocess(new_frame))\n",
    "                      reward += r                    \n",
    "\n",
    "                #Save to history\n",
    "                self.reward_history.append(reward)\n",
    "                self.state_history.append(np.dstack(s))\n",
    "                self.action_history.append(a)\n",
    "                self.next_state_history.append(np.dstack(s_prime))\n",
    "                self.done_history.append(done)\n",
    "                 \n",
    "                if len(self.reward_history)>32 and self.steps_taken%4==0:\n",
    "                    self.gradient_update(self.runname,\n",
    "                                         self.state_history, \n",
    "                                         self.next_state_history,\n",
    "                                         self.reward_history,\n",
    "                                         self.action_history,\n",
    "                                         self.loss_history,\n",
    "                                         self.behavior, \n",
    "                                         self.target,\n",
    "                                         self.gamma,\n",
    "                                         self.batch_size,\n",
    "                                         self.done_history,\n",
    "                                         self.action_space)\n",
    "                    \n",
    "                if self.steps_taken%10000==0:\n",
    "                    self.target.toymodel.set_weights(self.behavior.toymodel.get_weights())   \n",
    "\n",
    "                if np.random.random() < np.max([self.epsilon,self.epsilon_min]):\n",
    "                    a_prime = np.random.choice(np.arange(len(self.action_space)))\n",
    "                else:\n",
    "                    a_probs = self.behavior.toymodel(np.expand_dims(np.dstack(s_prime),0), training=False)\n",
    "                    a_prime = tf.argmax(a_probs[0]).numpy()\n",
    "                    #print ('Nonrandom action taken. ', a_prime)\n",
    "\n",
    "                s = s_prime\n",
    "                a = a_prime\n",
    "                self.steps_taken += 1\n",
    "                self.memory_manager(self.action_history, self.max_memory_len)\n",
    "                self.memory_manager(self.state_history, self.max_memory_len)\n",
    "                self.memory_manager(self.next_state_history, self.max_memory_len)\n",
    "                self.memory_manager(self.reward_history, self.max_memory_len)\n",
    "                self.memory_manager(self.done_history, self.max_memory_len)\n",
    "            #self.save_history(self.runname,\n",
    "            #                  self.action_history,\n",
    "            #                  self.state_history,\n",
    "            #                  self.next_state_history,\n",
    "            #                  self.reward_history,\n",
    "            #                  self.done_history,\n",
    "            #                  self.return_history)\n",
    "            self.episodic_return.append(epi_return)\n",
    "            print (\"Episode complete.\")\n",
    "            #self.env.close()\n",
    "            clear_output()\n",
    "            plt.figure(figsize=(5,5))\n",
    "            plt.plot(np.arange(len(self.episodic_return)), self.episodic_return)\n",
    "            plt.xlabel('Episode')\n",
    "            plt.ylabel('Return')\n",
    "            plt.show()\n",
    "            plt.figure(figsize=(5,5))\n",
    "            plt.plot(np.arange(len(self.loss_history)), self.loss_history)\n",
    "            plt.xlabel('Training Step')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.show()\n",
    "        #self.behavior.toymodel.save('120228_Breakout')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env1 = gym.make('BreakoutNoFrameskip-v4')\n",
    "atari_action_space = np.arange(4)\n",
    "# 'BreakoutNoFrameskip-v4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent_4Frame('210228_1', env1, atari_action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epsilon is at  0.3689775999999999  as of step  701136\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\VGBOT\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__float__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    977\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__float__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VGBOT\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1028\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-6939a957ac9d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-3fdd3eee7745>\u001b[0m in \u001b[0;36mepisode\u001b[1;34m(self, num_episodes)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreward_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m32\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps_taken\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                     self.gradient_update(self.runname,\n\u001b[0m\u001b[0;32m    178\u001b[0m                                          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                                          \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext_state_history\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-3fdd3eee7745>\u001b[0m in \u001b[0;36mgradient_update\u001b[1;34m(self, runname, state_history, next_state_history, rewards_history, action_history, loss_history, model, target_model, gamma, batch_size, done_history, action_space)\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoymodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoymodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'loss_function_history'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_history\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     def save_history(self,\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msave\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VGBOT\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(file, arr, allow_pickle, fix_imports)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m         format.write_array(fid, arr, allow_pickle=allow_pickle,\n\u001b[0;32m    553\u001b[0m                            pickle_kwargs=pickle_kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\VGBOT\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \"\"\"\n\u001b[1;32m--> 138\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "agent.episode(100000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\cooki_l8i2983\\Anaconda3\\envs\\VGBOT\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From C:\\Users\\cooki_l8i2983\\Anaconda3\\envs\\VGBOT\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: 210402_behavior\\assets\n",
      "INFO:tensorflow:Assets written to: 210402_target\\assets\n"
     ]
    }
   ],
   "source": [
    "agent.behavior.toymodel.save('210402_behavior')\n",
    "agent.target.toymodel.save('210402_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
