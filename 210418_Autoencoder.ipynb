{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import logging\n",
    "#import retro\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import keyboard\n",
    "import gym\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import clear_output\n",
    "#retro.data.list_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE():\n",
    "  def __init__(self, action_space):\n",
    "    self.action_space = len(action_space)\n",
    "    image_input = layers.Input(shape=(84,84, 1))\n",
    "    #preprocessor = layers.experimental.preprocessing.Resizing(84, 84, interpolation='bilinear', name=None)(image_input)\n",
    "    # Convolutions on the frames on the screen\n",
    "    #data_format='channels_first'\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(image_input)\n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "    layer6 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "    layer7 = layers.Dense(3, activation=\"relu\")(layer6)\n",
    "    upsample = layers.Dense(7*7*64)(layer7)\n",
    "    layer8 = layers.Reshape((7, 7, 64))(upsample)\n",
    "    layer9 = layers.Conv2DTranspose(64,3, activation=\"relu\")(layer8)\n",
    "    layer10 = layers.Conv2DTranspose(32,12, activation=\"relu\")(layer9)\n",
    "    layer11 = layers.Conv2DTranspose(1,65, activation=\"relu\")(layer10)\n",
    "\n",
    "    #Define NN parameters.\n",
    "    self.toymodel = keras.Model(inputs=image_input, outputs=layer11)\n",
    "    self.loss_fn = tf.keras.losses.Huber()\n",
    "    self.optimizer = keras.optimizers.Adam(learning_rate=0.0000625)\n",
    "    self.toymodel.compile(self.optimizer, self.loss_fn)\n",
    "\n",
    "  def trainStep(self, sample_X, sample_Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      old_q = self.toymodel(sample_X, training=True)\n",
    "      loss_value = self.loss_fn(sample_Y, old_q)\n",
    "    grads = tape.gradient(loss_value, self.toymodel.trainable_weights)\n",
    "    self.optimizer.apply_gradients(zip(grads, self.toymodel.trainable_weights))\n",
    "    return loss_value.numpy()\n",
    "\n",
    "  def train(self, x_input, y_input, batchsize=64):\n",
    "    loss_history = []\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_input, y_input))\n",
    "    dataset = dataset.shuffle(buffer_size=1024).batch(batchsize)\n",
    "    for steps, (x, y) in enumerate(dataset):\n",
    "      loss_history.append(self.trainStep(x,y))\n",
    "    return loss_history\n",
    "\n",
    "  def forward(self, x_input):\n",
    "    return self.toymodel(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_31 (InputLayer)        [(None, 84, 84, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 20, 20, 32)        2080      \n",
      "_________________________________________________________________\n",
      "conv2d_42 (Conv2D)           (None, 9, 9, 64)          32832     \n",
      "_________________________________________________________________\n",
      "conv2d_43 (Conv2D)           (None, 7, 7, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 3)                 1539      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 3136)              12544     \n",
      "_________________________________________________________________\n",
      "reshape_8 (Reshape)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_21 (Conv2DT (None, 9, 9, 64)          36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_22 (Conv2DT (None, 20, 20, 32)        294944    \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_23 (Conv2DT (None, 84, 84, 1)         135201    \n",
      "=================================================================\n",
      "Total params: 2,159,140\n",
      "Trainable params: 2,159,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutNoFrameskip-v4')\n",
    "action_space = [0,2,3]\n",
    "test = VAE(action_space)\n",
    "test.toymodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "behavior = keras.models.load_model('D:\\\\ML_projects\\\\VGBOT\\\\210414_1_An_DQN_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_NN(env, 0.01, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
