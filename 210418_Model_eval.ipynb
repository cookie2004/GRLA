{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import retro\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The agent was a double DQN. The two networks are:\n",
    "#1. Behavior - Makes action predictions and is updated every 16 frames\n",
    "#2. Target - Makes predictions on the future return\n",
    "\n",
    "#Point the string to the directory of the target network!\n",
    "target = keras.models.load_model('210612_1_SMB_DQN_target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Repeats actions frameskips number of times. Stacks the same number of images. \n",
    "#The stacked array of images is the final input for the DQN.\n",
    "def RGB_preprocess(action, env, frameskips):\n",
    "    state_output = []\n",
    "    reward = 0\n",
    "    for i in range(frameskips):\n",
    "        s, r, d, info = env.step(action)\n",
    "        #Accumulate any rewards given during action repeats.\n",
    "        reward += r\n",
    "        #Grayscale the images.\n",
    "        s = cv2.cvtColor(s, cv2.COLOR_RGB2GRAY)\n",
    "        #Resize the images to a square 84x84.\n",
    "        s = cv2.resize(s, (84, 84), interpolation=cv2.INTER_AREA)\n",
    "        #Scale pixel values to a maximum of 1 by dividing by 255.\n",
    "        state_output.append(s/255.0)\n",
    "    return np.dstack(state_output).astype('float16'), reward, d, info\n",
    "\n",
    "#The video is a stack of matplotlib figure frames. Each figure frame is created through the diag_output function.\n",
    "#This function is tailored to my specific DQN. You will have to modify this function if your DQN is of a different architecture.\n",
    "def diag_output(s, peeled_layers, scalar_layers, episode_return):\n",
    "    \n",
    "    #Create the matplotlib figure. I find GridSpec to be the easiest way to customize the layout\n",
    "    # of my plots.\n",
    "    \n",
    "    fig = plt.figure(figsize=(25, 20))\n",
    "    fig.patch.set_facecolor('black')\n",
    "    gs = GridSpec(nrows=6, ncols=4)\n",
    "\n",
    "    #Raw observation\n",
    "    ax0 = fig.add_subplot(gs[0:4, 0:2]) \n",
    "    ax0.axis('off')\n",
    "    ax0.imshow(s)\n",
    "    ax0.set_title('Raw observation', color='white', fontsize=25)\n",
    "\n",
    "    #Preprocessing - 4-frame stack input for the NN\n",
    "    ax1 = fig.add_subplot(gs[0,2:])\n",
    "    ax1.set_xlim(0,84*4)\n",
    "    ax1.axis('off')\n",
    "    for i in range(len(peeled_layers[0])):   \n",
    "        ax1.imshow(peeled_layers[0][i], origin='upper',extent=[i*84,i*84+84, 0, 84])\n",
    "        ax1.plot([i*84,i*84],[0,84],color='black')\n",
    "    ax1.set_title('Preprocessing - 84x84, 4-frame stack', color='white', fontsize=25)\n",
    "    \n",
    "    #First Conv2D layer\n",
    "    ax2 = fig.add_subplot(gs[1,2:])\n",
    "    ax2.axis('off')\n",
    "    for i in range(len(peeled_layers[1])):   \n",
    "        ax2.imshow(peeled_layers[1][i], origin='upper',extent=[int(i%8)*20,int(i%8)*20+20, int(i/8)*20, int(i/8)*20+20])\n",
    "        ax2.plot([int(i%8)*20,int(i%8)*20],[int(i/8)*20,int(i/8)*20+20],color='black')\n",
    "        #ax2.set_ylim(len(peeled_layers[1]*20))\n",
    "    ax2.set_title('Conv2D layer - 20x20x32', color='white', fontsize=25)\n",
    "\n",
    "    #Second Conv2D layer\n",
    "    ax3 = fig.add_subplot(gs[2,2:])\n",
    "    ax3.axis('off')\n",
    "    for i in range(len(peeled_layers[2])):   \n",
    "        ax3.imshow(peeled_layers[2][i], origin='upper',extent=[int(i%16)*9,int(i%16)*9+9, int(i/16)*9, int(i/16)*9+9])\n",
    "        ax3.plot([int(i%16)*9,int(i%16)*9],[int(i/16)*9,int(i/16)*9+9],color='black')\n",
    "    ax3.set_title('Conv2D layer - 9x9x64', color='white', fontsize=25)\n",
    "\n",
    "    #Third Conv2D layer\n",
    "    ax4 = fig.add_subplot(gs[3,2:])\n",
    "    ax4.axis('off')\n",
    "    for i in range(len(peeled_layers[3])):   \n",
    "        ax4.imshow(peeled_layers[3][i], origin='upper',extent=[int(i%16)*7,int(i%16)*7+7, int(i/16)*7, int(i/16)*7+7])\n",
    "        ax4.plot([int(i%16)*7,int(i%16)*7],[int(i/16)*7,int(i/16)*7+7],color='black')\n",
    "    ax4.set_title('Conv2D layer - 7x7x64', color='white', fontsize=25)\n",
    "\n",
    "    #Flatten layer\n",
    "    ax5 = fig.add_subplot(gs[4,2:])\n",
    "    ax5.axis('off')\n",
    "    ax5.imshow(np.reshape(scalar_layers[0],(32,98)))\n",
    "    ax5.set_title('Flatten layer - 1x3136', color='white', fontsize=25)\n",
    "\n",
    "    #Dense layer\n",
    "    ax6 = fig.add_subplot(gs[5,2:])\n",
    "    ax6.axis('off')\n",
    "    ax6.imshow(np.reshape(scalar_layers[1],(8,64)))\n",
    "    ax6.set_title('Dense layer - 1x512', color='white', fontsize=25)\n",
    "\n",
    "    #Output layer of neural network showing predicted value of each actions (Q value)\n",
    "    ax7 = fig.add_subplot(gs[4:,0])\n",
    "    ax7.bar(np.arange(len(scalar_layers[2][0])),scalar_layers[2][0], edgecolor='white', color='black', width=0.25, linewidth=2.0)\n",
    "    ax7.set_ylabel('Q value', fontsize=25, color='white')\n",
    "    ax7.set_xlabel('Action', fontsize=25, color='white')\n",
    "    ax7.tick_params(axis='both', labelsize=25, color='white', labelcolor='white')\n",
    "    ax7.set_facecolor('black')\n",
    "    ax7.spines['bottom'].set_color('white')\n",
    "    ax7.spines['top'].set_color('white')\n",
    "    ax7.spines['left'].set_color('white')\n",
    "    ax7.spines['right'].set_color('white')\n",
    "\n",
    "    #Reward accumulated throughout the episode.\n",
    "    ax8 = fig.add_subplot(gs[4:,1])\n",
    "    ax8.plot(episode_return, color='white', linewidth=2.0)\n",
    "    ax8.set_ylabel('Cumulative Reward', fontsize=25, color='white')\n",
    "    ax8.set_xlabel('Step', fontsize=25, color='white')\n",
    "    ax8.tick_params(axis='x', labelsize=25, color='white', labelcolor='white')\n",
    "    ax8.tick_params(axis='y', which='both', labelleft=False)\n",
    "    ax8.set_facecolor('black')\n",
    "    ax8.spines['bottom'].set_color('white')\n",
    "    ax8.spines['top'].set_color('white')\n",
    "    ax8.spines['left'].set_color('white')\n",
    "    ax8.spines['right'].set_color('white') \n",
    "    \n",
    "    #These lines convert the matplotlib figure into a numpy image array. \n",
    "    canvas = FigureCanvas(fig)\n",
    "    canvas.draw()  \n",
    "    width, height = fig.get_size_inches() * fig.get_dpi()\n",
    "    image = np.fromstring(canvas.tostring_rgb(), dtype='uint8').reshape(int(height), int(width), 3)\n",
    "    return image\n",
    "\n",
    "def visual_evaluate_NN(output_name, env, epsilon, replicates, model, max_steps):\n",
    "    av_returns = []\n",
    "    #Unwrap layers to get intermediate outputs.\n",
    "    inp = model.input\n",
    "    outputs = [layer.output for layer in model.layers]\n",
    "    functors = K.function(inp, outputs)\n",
    "    \n",
    "    #Create video object. We will write the frames to this object.\n",
    "    out = cv2.VideoWriter(output_name+'.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 60/frameskips, (1800,1440))\n",
    "\n",
    "    #You have to reset the environment to the start of the level.\n",
    "    s = env.reset()\n",
    "    #Prime the frame stack. I chose the first action. \n",
    "    s, episode_return, done, info = RGB_preprocess(action_space[0], env, frameskips)\n",
    "    episode_return = 0\n",
    "    return_list = [0]\n",
    "    done = False\n",
    "    lives = int(info['lives'])\n",
    "    #Run through Q-learning algorithm loop until the max number of steps is reached or Mario dies. :-(\n",
    "    for num_of_steps in range(max_steps):\n",
    "        if num_of_steps%5==0: \n",
    "            clear_output()\n",
    "            print ('Step: ', num_of_steps)\n",
    "   \n",
    "        #Choose epsilon greedy action.\n",
    "        if np.random.random() < epsilon:\n",
    "            a = np.random.choice(np.arange(len(action_space)))\n",
    "        else: \n",
    "            a_probs = model(np.expand_dims(s,0), training=False)\n",
    "            a = tf.argmax(a_probs[0]).numpy()\n",
    "            \n",
    "        #Collect information on next state.\n",
    "        s, reward, done, info = RGB_preprocess(action_space[a], env, frameskips)\n",
    "        raw_obs = env.get_screen()[:, :, [0, 1, 2]]\n",
    "\n",
    "        episode_return += reward\n",
    "        return_list.append(episode_return)\n",
    "        \n",
    "        #Run the state through the functors for intermediate output plots.\n",
    "        layer_outs = functors([np.expand_dims(s,0), 1.])\n",
    "        peeled_layers = []\n",
    "        scalar_layers = layer_outs[4:]\n",
    "        images = []\n",
    "        #The first 4 layers of the DQN are images. So, we need to unravel the values into individual features. \n",
    "        #The other layers have 1D arrays as outputs. Thus, there is no specific way to display this values in our plots.\n",
    "        for i in layer_outs[0:4]:\n",
    "            images = [i[0][:,:,j] for j in range(len(i[0][0][0]))]\n",
    "            peeled_layers.append(images) \n",
    "            \n",
    "        #Create the image from the output of each layer using diag_output\n",
    "        image = diag_output(raw_obs, peeled_layers, scalar_layers, return_list)\n",
    "        \n",
    "        #CV2 arranges the channels as BGR. We need to write the matplotlib figure as RGB by rearranging the channels.\n",
    "        out.write(image[:, :, [2, 1, 0]])\n",
    "        plt.close()\n",
    "        #If a life was lost, end the episode. This will result in a video of a single Mario life rather than all available lives.\n",
    "        if not (int(info['lives']) == lives):                                         \n",
    "            lives = int(info['lives'])\n",
    "            s, reward, done, info = RGB_preprocess(action_space[0], env, frameskips)\n",
    "            av_returns.append(episode_return)  \n",
    "            episode_return = 0 \n",
    "            break\n",
    "        if done:\n",
    "            av_returns.append(episode_return)   \n",
    "            break   \n",
    "    #Release the video object. \n",
    "    out.release()\n",
    "    clear_output()\n",
    "    print ('Evaluation complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete.\n"
     ]
    }
   ],
   "source": [
    "#Create a new environment. \n",
    "#env.close()\n",
    "env = retro.make(game='SuperMarioBros-Nes')\n",
    "\n",
    "#Actions are repeated over 4 frames. These 4 frames are used as input for the next action value prediction.\n",
    "frameskips = 4\n",
    "epsilon = 0.02\n",
    "\n",
    "#Only 4 actions are available to the agent. Move left, move right, jump left, and jump right. \n",
    "action_space = [[0,0,0,0,0,0,1,0,0],\n",
    "                [0,0,0,0,0,0,0,1,0],\n",
    "                [0,0,0,0,0,0,1,0,1],\n",
    "                [0,0,0,0,0,0,0,1,1]]\n",
    "\n",
    "#Run the visual_evaluate_NN function. \n",
    "visual_evaluate_NN('test', env, epsilon, 1, target, 10000)\n",
    "\n",
    "#You can only have one retro env open at a time. Make sure to close any previously opened envs. \n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
