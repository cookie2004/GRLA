{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import threading\n",
    "import logging\n",
    "#import retro\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import initializers\n",
    "from sklearn.preprocessing import scale\n",
    "import numpy as np\n",
    "import cv2\n",
    "import numpy as np\n",
    "#import keyboard\n",
    "import gym\n",
    "import matplotlib.pylab as plt\n",
    "from IPython.display import clear_output\n",
    "#retro.data.list_games()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs, rew, done, info = env.step(env.action_space.sample())\n",
    "#(224, 240, 3)\n",
    "#MultiBinary(9)                          \n",
    "class RAM_ANN():\n",
    "  def __init__(self, action_space, frameskip, seed):\n",
    "    self.seed = seed\n",
    "    initializer1 = initializers.GlorotUniform (seed = self.seed+1)\n",
    "    initializer2 = initializers.GlorotUniform (seed = self.seed+2)\n",
    "    initializer3 = initializers.GlorotUniform (seed = self.seed+3)\n",
    "    initializer4 = initializers.GlorotUniform (seed = self.seed+4)\n",
    "    self.frameskip = frameskip\n",
    "    self.action_space = len(action_space)\n",
    "    num_actions = self.action_space\n",
    "    #NN layers\n",
    "    ram_input = layers.Input(shape=(128))\n",
    "    #preprocessor = layers.experimental.preprocessing.Resizing(84, 84, interpolation='bilinear', name=None)(image_input)\n",
    "    # Convolutions on the frames on the screen\n",
    "    #data_format='channels_first'\n",
    "    layer5 = layers.Dense(128, activation=\"relu\", kernel_initializer = initializer1)(ram_input)\n",
    "    layer6 = layers.Dense(256, activation=\"relu\", kernel_initializer = initializer2)(layer5)\n",
    "    layer7 = layers.Dense(128, activation=\"relu\", kernel_initializer = initializer3)(layer6)\n",
    "    action = layers.Dense(num_actions, activation=\"linear\", kernel_initializer = initializer4)(layer7)\n",
    "\n",
    "    #Define NN parameters.\n",
    "    self.toymodel = keras.Model(inputs=ram_input, outputs=action)\n",
    "    self.loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "    self.optimizer = keras.optimizers.Adam(learning_rate=0.0001, clipnorm=1.0)\n",
    "    self.toymodel.compile(self.optimizer, self.loss_fn)\n",
    "\n",
    "  def trainStep(self, sample_X, sample_Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      old_q = self.toymodel(sample_X, training=True)\n",
    "      loss_value = self.loss_fn(sample_Y, old_q)\n",
    "    grads = tape.gradient(loss_value, self.toymodel.trainable_weights)\n",
    "    self.optimizer.apply_gradients(zip(grads, self.toymodel.trainable_weights))\n",
    "    return loss_value.numpy()\n",
    "\n",
    "  def train(self, x_input, y_input, batchsize=64):\n",
    "    loss_history = []\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_input, y_input))\n",
    "    dataset = dataset.shuffle(buffer_size=1024).batch(batchsize)\n",
    "    for steps, (x, y) in enumerate(dataset):\n",
    "      loss_history.append(self.trainStep(x,y))\n",
    "    return loss_history\n",
    "\n",
    "  def forward(self, x_input):\n",
    "    return self.toymodel(x_input)\n",
    "\n",
    "class ANN():\n",
    "  def __init__(self, action_space, frameskip):\n",
    "    self.frameskip = frameskip\n",
    "    self.action_space = len(action_space)\n",
    "    num_actions = self.action_space\n",
    "    #NN layers\n",
    "    image_input = layers.Input(shape=(84,84,self.frameskip))\n",
    "    #preprocessor = layers.experimental.preprocessing.Resizing(84, 84, interpolation='bilinear', name=None)(image_input)\n",
    "    # Convolutions on the frames on the screen\n",
    "    #data_format='channels_first'\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(image_input)\n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "    layer5 = layers.Dense(512, activation=\"relu\")(layer4)\n",
    "\n",
    "    action = layers.Dense(num_actions, activation=\"linear\")(layer5)\n",
    "\n",
    "    #Define NN parameters.\n",
    "    self.toymodel = keras.Model(inputs=image_input, outputs=action)\n",
    "    self.loss_fn = tf.keras.losses.Huber()\n",
    "    self.optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "    self.toymodel.compile(self.optimizer, self.loss_fn)\n",
    "\n",
    "  def trainStep(self, sample_X, sample_Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      old_q = self.toymodel(sample_X, training=True)\n",
    "      loss_value = self.loss_fn(sample_Y, old_q)\n",
    "    grads = tape.gradient(loss_value, self.toymodel.trainable_weights)\n",
    "    self.optimizer.apply_gradients(zip(grads, self.toymodel.trainable_weights))\n",
    "    return loss_value.numpy()\n",
    "\n",
    "  def train(self, x_input, y_input, batchsize=64):\n",
    "    loss_history = []\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_input, y_input))\n",
    "    dataset = dataset.shuffle(buffer_size=1024).batch(batchsize)\n",
    "    for steps, (x, y) in enumerate(dataset):\n",
    "      loss_history.append(self.trainStep(x,y))\n",
    "    return loss_history\n",
    "\n",
    "  def forward(self, x_input):\n",
    "    return self.toymodel(x_input)\n",
    "\n",
    "class LookAhead():\n",
    "  def __init__(self, action_space):\n",
    "    self.action_space = len(action_space)\n",
    "    image_input = layers.Input(shape=(84,84,4))\n",
    "    action_input = layers.Input(shape=self.action_space)\n",
    "    #preprocessor = layers.experimental.preprocessing.Resizing(84, 84, interpolation='bilinear', name=None)(image_input)\n",
    "    # Convolutions on the frames on the screen\n",
    "    #data_format='channels_first'\n",
    "    layer1 = layers.Conv2D(32, 8, strides=4, activation=\"relu\")(image_input)\n",
    "    layer2 = layers.Conv2D(64, 4, strides=2, activation=\"relu\")(layer1)\n",
    "    layer3 = layers.Conv2D(64, 3, strides=1, activation=\"relu\")(layer2)\n",
    "    layer4 = layers.Flatten()(layer3)\n",
    "    layer5 = layers.Concatenate(axis=1)([layer4, action_input])\n",
    "    layer6 = layers.Dense(512, activation=\"relu\")(layer5)\n",
    "    layer7 = layers.Dense(3136, activation=\"relu\")(layer6)\n",
    "    layer8 = layers.Reshape((7, 7, 64))(layer7)\n",
    "    layer9 = layers.Conv2DTranspose(64,3)(layer8)\n",
    "    layer10 = layers.Conv2DTranspose(32,12)(layer9)\n",
    "    layer11 = layers.Conv2DTranspose(4,65)(layer10)\n",
    "    value_output = layers.Dense(1, activation='linear')(layer5)\n",
    "\n",
    "    #Define NN parameters.\n",
    "    toymodel = keras.Model(inputs=[image_input, action_input], outputs=[layer11, value_output])\n",
    "    loss_fn = tf.keras.losses.Huber()\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=0.00025)\n",
    "    toymodel.compile(optimizer, loss_fn)\n",
    "\n",
    "  def trainStep(self, sample_X, sample_Y):\n",
    "    with tf.GradientTape() as tape:\n",
    "      old_q = self.toymodel(sample_X, training=True)\n",
    "      loss_value = self.loss_fn(sample_Y, old_q)\n",
    "    grads = tape.gradient(loss_value, self.toymodel.trainable_weights)\n",
    "    self.optimizer.apply_gradients(zip(grads, self.toymodel.trainable_weights))\n",
    "    return loss_value.numpy()\n",
    "\n",
    "  def train(self, x_input, y_input, batchsize=64):\n",
    "    loss_history = []\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x_input, y_input))\n",
    "    dataset = dataset.shuffle(buffer_size=1024).batch(batchsize)\n",
    "    for steps, (x, y) in enumerate(dataset):\n",
    "      loss_history.append(self.trainStep(x,y))\n",
    "    return loss_history\n",
    "\n",
    "  def forward(self, x_input):\n",
    "    return self.toymodel(x_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title\n",
    "class Agent_RAM():\n",
    "    def __init__(self,runname, action_space, num_of_threads = 1, rom_name = 'Breakout-ram-v4'):\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.num_of_threads = int(num_of_threads)\n",
    "        self.steps_taken = 0 \n",
    "        self.runname = runname\n",
    "        self.len_of_episode = 10000\n",
    "        \n",
    "        #Set hyperparameters.\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_max = 1.0\n",
    "        self.epsilon_min = 0\n",
    "        self.epsilon_lag = 50000\n",
    "        self.annealing_time = 1000000\n",
    "        self.gamma = 0.99\n",
    "        self.max_memory_len = 1000000\n",
    "        self.batch_size = 32\n",
    "        self.steps_per_update = 100\n",
    "        self.reward_scaler = 0.01\n",
    "        self.target_update = 10000\n",
    "        self.window = 25\n",
    "        self.frameskip = 1 #Deprecated for the moment and needs updating\n",
    "        \n",
    "        #Initialize containers which will be prepared in thread_prep()\n",
    "        self.loss_history = []\n",
    "        self.action_history = []\n",
    "        self.state_history= []\n",
    "        self.next_state_history = []\n",
    "        self.reward_history = []\n",
    "        self.done_history = []\n",
    "        self.episodic_return = []\n",
    "        self.return_history = [] \n",
    "        self.env_container = []\n",
    "        self.threads = []\n",
    "        self.epsilon_schedule = []\n",
    "        self.thread_prep(rom_name)\n",
    "\n",
    "        #Initialize target and behavior network.\n",
    "        self.seed = 42\n",
    "        self.behavior = RAM_ANN(self.action_space, self.frameskip, self.seed)\n",
    "        self.target = RAM_ANN(self.action_space,self.frameskip,self.seed)\n",
    "        \n",
    "    def popback(self, state_block, incoming_state):\n",
    "        state_block.pop(0)\n",
    "        state_block.append(incoming_state)\n",
    "        return state_block\n",
    "\n",
    "    def gradient_update(self, \n",
    "                        runname,\n",
    "                        state_history, \n",
    "                        next_state_history,\n",
    "                        rewards_history,\n",
    "                        action_history,\n",
    "                        loss_history,\n",
    "                        model,\n",
    "                        target_model,\n",
    "                        gamma,\n",
    "                        batch_size,\n",
    "                        done_history,\n",
    "                        action_space):\n",
    "    \n",
    "            # Get indices of samples for replay buffers\n",
    "            indices = np.random.choice(range(len(done_history)), size=batch_size)\n",
    "            # Using list comprehension to sample from replay buffer\n",
    "            state_sample = np.array([state_history[i] for i in indices])\n",
    "            next_state_sample = np.array([next_state_history[i] for i in indices])\n",
    "            rewards_sample = [rewards_history[i] for i in indices]\n",
    "            action_sample = [action_history[i] for i in indices]\n",
    "            done_sample = tf.convert_to_tensor([float(done_history[i]) for i in indices])\n",
    "            future_rewards = target_model.toymodel.predict(next_state_sample)\n",
    "            updated_q_values = rewards_sample + gamma * tf.reduce_max(future_rewards)\n",
    "            updated_q_values = updated_q_values *(1-done_sample) - done_sample\n",
    "            masks = tf.one_hot(action_sample, len(action_space))\n",
    "            with tf.GradientTape() as tape:  \n",
    "                q_values = model.toymodel(state_sample)\n",
    "                q_actions = tf.reduce_sum(tf.multiply(q_values, masks), axis=1)\n",
    "                loss = model.loss_fn(updated_q_values, q_actions)\n",
    "            loss_history = loss_history.append(loss)\n",
    "            grads = tape.gradient(loss, model.toymodel.trainable_variables)\n",
    "            model.toymodel.optimizer.apply_gradients(zip(grads, model.toymodel.trainable_variables))\n",
    "\n",
    "    def softmax(Ht):\n",
    "      output = []\n",
    "      for j in Ht:\n",
    "        numerator = np.exp(j)\n",
    "        demoninator = 0\n",
    "        for i in range(len(Ht)):\n",
    "          demoninator += np.exp(Ht[i])\n",
    "        output.append(numerator/demoninator)\n",
    "      return output  \n",
    "\n",
    "    def save_history(self,\n",
    "                     runname,\n",
    "                     action_history,\n",
    "                     state_history,\n",
    "                     next_state_history,\n",
    "                     reward_history,\n",
    "                     done_history,\n",
    "                     return_history):            \n",
    "        np.save(runname + 'action_history',action_history)\n",
    "        np.save(runname + 'state_history', state_history)\n",
    "        np.save(runname + 'next_state_history', next_state_history)\n",
    "        np.save(runname + 'reward_history', reward_history)\n",
    "        np.save(runname + 'done_history', done_history)\n",
    "        np.save(runname + 'return_history', return_history)   \n",
    "\n",
    "    def preprocess(self, state):\n",
    "        #return [state[0]/4.8, state[1], state[2]/0.418, state[3]] #CartPole parameters\n",
    "        return state/255\n",
    "\n",
    "    def memory_manager(self,array, mem_size):\n",
    "        num_delete = len(array) - mem_size\n",
    "        if num_delete < 0:\n",
    "            None\n",
    "        else:\n",
    "            del array[:num_delete]\n",
    "            \n",
    "    def piecewise_epsilon(self, steps_taken, lag, annealingtime, ep_min, ep_max): #returns epsilon\n",
    "        anneal_slope= (ep_min-ep_max)/(lag+annealingtime-lag)\n",
    "        if steps_taken < lag: return ep_max\n",
    "        if (steps_taken >= lag) and (steps_taken < (lag+annealingtime)): return anneal_slope*steps_taken+(ep_max-anneal_slope*lag)\n",
    "        else: return ep_min\n",
    "\n",
    "    def sliding_average(self, array, n):\n",
    "        output = []\n",
    "        for i in range(len(array)):\n",
    "            try:\n",
    "                output.append(np.average(array[i:i+n]))\n",
    "            except IndexError:\n",
    "                break\n",
    "        return output\n",
    "    \n",
    "    def thread_prep(self, rom_name):\n",
    "        self.loss_history = [[] for i in range(self.num_of_threads)]\n",
    "        self.action_history = [[] for i in range(self.num_of_threads)]\n",
    "        self.state_history = [[] for i in range(self.num_of_threads)]\n",
    "        self.next_state_history = [[] for i in range(self.num_of_threads)]\n",
    "        self.reward_history = [[] for i in range(self.num_of_threads)]\n",
    "        self.done_history = [[] for i in range(self.num_of_threads)]\n",
    "        self.episodic_return = [[] for i in range(self.num_of_threads)]\n",
    "        self.return_history = [[] for i in range(self.num_of_threads)]\n",
    "        self.env_container = [gym.make(rom_name) for i in range(self.num_of_threads)]\n",
    "        self.steps_taken = [0 for i in range(self.num_of_threads)]\n",
    "        self.epsilon_schedule = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "        \n",
    "        \n",
    "    def agent_thread(self, thread_num, episodes, seed=42):\n",
    "        logging.info(\"Thread %s: starting\", thread_num)\n",
    "        env = self.env_container[thread_num]\n",
    "        self.env_container[thread_num].seed(seed)\n",
    "        self.episode(episodes, self.env_container[thread_num], thread_num, self.epsilon_schedule[thread_num])\n",
    "        logging.info(\"Thread %s: finishing\", thread_num)\n",
    "     \n",
    "    def start_threads(self, num_of_episodes=1):\n",
    "        format = \"%(asctime)s: %(message)s\"\n",
    "        logging.basicConfig(format=format, level=logging.INFO, datefmt=\"%H:%M:%S\")\n",
    "        for i in range(self.num_of_threads):\n",
    "            logging.info(\"Main    : create and start thread %d.\", i)\n",
    "            x = threading.Thread(target=self.agent_thread, args=(i, num_of_episodes))\n",
    "            self.threads.append(x)\n",
    "            x.start()\n",
    "                \n",
    "        while len(self.episodic_return[0]) < num_of_episodes:\n",
    "            self.plot_data()\n",
    "            time.sleep(10)\n",
    "                            \n",
    "        for j in self.threads:\n",
    "            j.join()\n",
    "\n",
    "        self.plot_data()\n",
    "        \n",
    "    def plot_data(self,):\n",
    "        clear_output()\n",
    "        plt.figure(figsize=(10,2))\n",
    "        for i in range(self.num_of_threads):\n",
    "            plt.plot(self.episodic_return[i], label='Thread ' + str(i))\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel('Return')\n",
    "        plt.legend(loc=7)\n",
    "        plt.show()\n",
    "        \n",
    "        plt.figure(figsize=(10,2))\n",
    "        for i in range(self.num_of_threads):\n",
    "            plt.plot(self.sliding_average(self.episodic_return[i], self.window), label='Thread '+str(i))\n",
    "        plt.xlabel('Episode')\n",
    "        plt.ylabel(str(self.window)+'-averaged Return')\n",
    "        plt.legend(loc=7)\n",
    "        plt.show()\n",
    "\n",
    "        plt.figure(figsize=(10,2))\n",
    "        for i in range(self.num_of_threads):\n",
    "            plt.plot(self.loss_history[i], label='Thread '+str(i))\n",
    "        plt.xlabel('Training Step')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend(loc=7)\n",
    "        plt.show()\n",
    "            \n",
    "    def episode(self, num_episodes, env, thread_num, epsilon):    #Double Deep Q\n",
    "        #np.random.seed(self.seed)\n",
    "        epsilon = self.piecewise_epsilon(self.steps_taken[thread_num], self.epsilon_lag, self.annealing_time, self.epsilon_min, self.epsilon_max)\n",
    "        for i in range (num_episodes):\n",
    "            lives = 5     #5 for Breakout, 4 for Space Invaders\n",
    "            epi_return = 0 \n",
    "            s = self.preprocess(env.reset())\n",
    "            done = False\n",
    "            #Enter the loop.\n",
    "            for step_in_episode in range (self.len_of_episode):\n",
    "                \n",
    "                #Choose an action from according to epsilson-greedy policy.  \n",
    "                if np.random.random() < epsilon:\n",
    "                    a = np.random.choice(np.arange(len(self.action_space)))\n",
    "                else: \n",
    "                    a_probs = self.behavior.toymodel(np.expand_dims(s,0), training=False)\n",
    "                    a = tf.argmax(a_probs[0]).numpy()\n",
    "                s_prime, reward, done, info = env.step(self.action_space[a])\n",
    "                s_prime = self.preprocess(s_prime)\n",
    "                epi_return += reward\n",
    "\n",
    "                #Restart when the end of the episode is reached.  \n",
    "                if done:                                                                              #FUNCTIONIZE!\n",
    "                    #Set the last frame to -1 to discourage dying.                                             \n",
    "                    self.done_history[thread_num][-1] = True \n",
    "                    self.reward_history[thread_num][-1] = -1\n",
    "                    self.episodic_return[thread_num].append(epi_return)\n",
    "                    break\n",
    "                \n",
    "                #Monitor the the number of lives from the environemtnt. If the number of lives is reduced, then the player has died. Reset the level.  FUNCTIONIZE!                \n",
    "                if not (int(info['ale.lives']) == lives):                                         \n",
    "                    self.done_history[thread_num][-1] = True \n",
    "                    self.episodic_return[thread_num].append(epi_return)\n",
    "                    break\n",
    "                \n",
    "                #Save to history\n",
    "                self.reward_history[thread_num].append(reward*self.reward_scaler)\n",
    "                self.state_history[thread_num].append(s)\n",
    "                self.action_history[thread_num].append(a)\n",
    "                self.next_state_history[thread_num].append(s_prime)\n",
    "                self.done_history[thread_num].append(done)\n",
    "                 \n",
    "                if self.steps_taken[thread_num]>self.batch_size and self.steps_taken[thread_num]%self.steps_per_update==0:\n",
    "                      self.gradient_update(self.runname,\n",
    "                                        self.state_history[thread_num], \n",
    "                                        self.next_state_history[thread_num],\n",
    "                                        self.reward_history[thread_num],\n",
    "                                        self.action_history[thread_num],\n",
    "                                        self.loss_history[thread_num],\n",
    "                                        self.behavior,\n",
    "                                        self.target,\n",
    "                                        self.gamma,\n",
    "                                        self.batch_size,\n",
    "                                        self.done_history[thread_num],\n",
    "                                        self.action_space) \n",
    "                        \n",
    "                        \n",
    "                if self.steps_taken[thread_num]%self.target_update==0:\n",
    "                    self.target.toymodel.set_weights(self.behavior.toymodel.get_weights()) \n",
    "\n",
    "                s = s_prime\n",
    "\n",
    "                self.steps_taken[thread_num] += 1\n",
    "                self.memory_manager(self.action_history[thread_num], self.max_memory_len)\n",
    "                self.memory_manager(self.state_history[thread_num], self.max_memory_len)\n",
    "                self.memory_manager(self.next_state_history[thread_num], self.max_memory_len)\n",
    "                self.memory_manager(self.reward_history[thread_num], self.max_memory_len)\n",
    "                self.memory_manager(self.done_history[thread_num], self.max_memory_len)\n",
    "            \n",
    "        env.close()\n",
    "\n",
    "\n",
    "        #self.behavior.toymodel.save('120228_Breakout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env1 = gym.make('Breakout-ram-v4')\n",
    "atari_action_space = np.arange(4)\n",
    "# 'BreakoutNoFrameskip-v4'\n",
    "# 'SpaceInvaders-v0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent_RAM('210405_1', atari_action_space, num_of_threads = 1)\n",
    "agent.epsilon = 1.0\n",
    "agent.epsilon_max = 1.0\n",
    "agent.epsilon_min = 0.05\n",
    "agent.epsilon_lag = 50000\n",
    "agent.annealing_time = 100000\n",
    "agent.len_of_episode = 10000\n",
    "agent.gamma = 0.99\n",
    "agent.max_memory_len = 1000000\n",
    "agent.batch_size = 32\n",
    "agent.steps_per_update = 32\n",
    "agent.reward_scaler = 1\n",
    "agent.target_update = 5000\n",
    "agent.epsilon_schedule = [0.05, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "#agent.episode(10000000, env1)\n",
    "#LR is 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-597c0e89281d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_threads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_of_episodes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40000000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-188ba6d3ad71>\u001b[0m in \u001b[0;36mstart_threads\u001b[1;34m(self, num_of_episodes)\u001b[0m\n\u001b[0;32m    165\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepisodic_return\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mnum_of_episodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 167\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreads\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "agent.start_threads(num_of_episodes=40000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
